{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e585c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() \n",
    "reg.fit(X_train, y_train)\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "np.round(reg_score,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret model coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a97b88",
   "metadata": {},
   "source": [
    "**Your task**: write down the linear regression model with the above coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a435a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 151.008 + 29.254 * age - 261.706 * sex + 546.3 * bmi + 388.398 * bp -901.96 * x1 + 506.763 * x2 + 121.154 * x3 + 288.03 * x4 + 659.269 * x5 + 41.377 * x6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**Your task**: explore other parameters/attributes/methods\n",
    "- fit_intercept\n",
    "- feature_names_in_, n_features_in_\n",
    "Write your exploration code and results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features:  10\n",
      "features names:  ['age' 'sex' 'bmi' 'bp' 's1' 's2' 's3' 's4' 's5' 's6']\n",
      "model score:  0.477\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"number of features: \", reg.n_features_in_)\n",
    "print(\"features names: \", reg.feature_names_in_)\n",
    "\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "print(\"model score: \", np.round(reg_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "np.round(rg_reg_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(rg_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Your task: fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c416398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "lasso_reg_score = lasso_reg.score(X_test, y_test)\n",
    "np.round(lasso_reg_score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   , 443.703,  51.601,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   , 201.966,   0.   ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lasso_reg.coef_,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad50fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.166"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lasso_reg.intercept_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Your task: compare the linear/ridge/lasso regression models\n",
    "- write down your code to create and display the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92e90c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure to: \n",
    "# - round to 3 digits after the decimal point\n",
    "# - rename the column names \n",
    "# - include intercept and score in the last two rows\n",
    "df = pd.DataFrame({\n",
    "    'linear': np.append(np.round(reg.coef_,3), [np.round(reg.intercept_,3), np.round(reg_score,3)]),\n",
    "    'ridge': np.append(np.round(rg_reg.coef_,3), [np.round(rg_reg.intercept_,3), np.round(rg_reg_score,3)]),\n",
    "    'lasso': np.append(np.round(lasso_reg.coef_,3), [np.round(lasso_reg.intercept_,3), np.round(lasso_reg_score,3)])\n",
    "})\n",
    "\n",
    "feature_names = list(reg.feature_names_in_)\n",
    "feature_names += ['intercept', 'score'] \n",
    "df.index = feature_names\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eadf9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization greatly reduces the model performance \n",
    "# L2 penalty shrinks some coefficients toward zero, while L1 penalty turns some coefficients to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models \n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63b3c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151.00821291456543, -360.91876865461967, 2.371636934848117e+16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Polynomial transformation for degree 1\n",
    "poly1 = PolynomialFeatures(degree=1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly1, y_train)\n",
    "intercept_poly1 = lin_reg.intercept_\n",
    "\n",
    "# Polynomial transformation for degree 2\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly2, y_train)\n",
    "intercept_poly2 = lin_reg.intercept_\n",
    "\n",
    "# Polynomial transformation for degree 3\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "lin_reg.fit(X_train_poly3, y_train)\n",
    "intercept_poly3 = lin_reg.intercept_\n",
    "\n",
    "(intercept_poly1, intercept_poly2, intercept_poly3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poly_d1': 0.4772897164322615,\n",
       " 'poly_d2': 0.4129770691622344,\n",
       " 'poly_d3': -92.5829427663642}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "for degree in range(1, 4):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    lin_reg.fit(X_train_poly, y_train)\n",
    "    scores[f'poly_d{degree}'] = lin_reg.score(X_test_poly, y_test)\n",
    "\n",
    "poly1_score = scores['poly_d1']\n",
    "poly2_score = scores['poly_d2']\n",
    "poly3_score = scores['poly_d3']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Your task: compare the polynomial regression models with degree=1/2/3 and the original linear regression model\n",
    "- please write code to create and display the given data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44f9e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>poly_d1</th>\n",
       "      <th>poly_d2</th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.008</td>\n",
       "      <td>-360.919</td>\n",
       "      <td>2.371637e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-9.258300e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear  poly_d1  poly_d2       poly_d3\n",
       "intercept  151.008  151.008 -360.919  2.371637e+16\n",
       "score        0.477    0.477    0.413 -9.258300e+01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'linear': [np.round(reg.intercept_,3), np.round(reg_score,3)],\n",
    "    'poly_d1': [np.round(intercept_poly1,3), np.round(poly1_score,3)],\n",
    "    'poly_d2': [np.round(intercept_poly2,3), np.round(poly2_score,3)],\n",
    "    'poly_d3': [np.round(intercept_poly3,3), np.round(poly3_score,3)]\n",
    "},\n",
    "\n",
    "index=['intercept', 'score'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your task: observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aba6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression is the same as polynomial regression with degree of 1\n",
    "# higher degrees may lead to overfitting, while lower degrees may lead to underfitting \n",
    "# degrees should be decided on the actual relationships in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Your task: interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute positively/negatively/most/least to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56641a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basded on linear and ridge models, age is positively correlated with diabetes, which makes sense from the aging standpoint\n",
    "# bmi and bp are consistently positive across models, and bmi seems to be the most influential features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('banknote_authentication_dataframe.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb9b2",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- L1 VS L2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e206acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb8b57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0baa21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2525662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [0.996, 0.004]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff19c",
   "metadata": {},
   "source": [
    "**Your task**: explore at least one different set of parameters to re-fit the model: solver, penalty, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "598e50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=0.2).fit(X_train, y_train)\n",
    "clf_test_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cf5ea6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_2 = LogisticRegression(random_state=0, solver='newton-cg', penalty='l2', C=0.2).fit(X_train, y_train)\n",
    "clf_test_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a43a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_test_3 = LogisticRegression(random_state=0, C=0.3).fit(X_train, y_train)\n",
    "clf_test_3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "     \n",
    "    # set the model parameter c to different values and train the model \n",
    "    # for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    #    fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "    #    test and record the model performance \n",
    "    #    get the statistical information about the model coefficients: \n",
    "    #        min: minimum coefficient\n",
    "    #        max: minimum coefficient\n",
    "    #        mean(abs(coef)): average over the absolute coefficient values\n",
    "    #        n_zero: number of coefficients equal to zero \n",
    "    \n",
    "    list = []\n",
    "    \n",
    "    # iterate through differnet c values \n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        clf = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', penalty=p, C=c).fit(X_train, y_train)\n",
    "        \n",
    "        # retrieve statistical info on coefficients\n",
    "        coef = clf.coef_\n",
    "        df = [c, coef.min(), coef.max(), abs(coef).mean(), (coef == 0).sum(), clf.score(X_test, y_test)]\n",
    "        \n",
    "        # create a dataframe for each model\n",
    "        df = pd.DataFrame(df).T\n",
    "        df.columns = [\"c\", \"min\", \"max\", \"mean_abs\", \"n_zero\", \"test_score\"]\n",
    "        list.append(df)\n",
    "    \n",
    "    # concatenate different dataframes \n",
    "    df = pd.concat(list)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return clf, df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7fb1b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357242</td>\n",
       "      <td>-0.074218</td>\n",
       "      <td>0.189712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.860815</td>\n",
       "      <td>-0.172662</td>\n",
       "      <td>0.485241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.580581</td>\n",
       "      <td>-0.162763</td>\n",
       "      <td>0.915028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.834711</td>\n",
       "      <td>-0.166099</td>\n",
       "      <td>1.645101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171020</td>\n",
       "      <td>-0.289579</td>\n",
       "      <td>2.936961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.647564</td>\n",
       "      <td>-0.437990</td>\n",
       "      <td>4.297064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c       min       max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.357242 -0.074218  0.189712     0.0    0.922330\n",
       "1    0.010 -0.860815 -0.172662  0.485241     0.0    0.973301\n",
       "2    0.100 -1.580581 -0.162763  0.915028     0.0    0.987864\n",
       "3    1.000 -2.834711 -0.166099  1.645101     0.0    0.987864\n",
       "4   10.000 -5.171020 -0.289579  2.936961     0.0    0.987864\n",
       "5  100.000 -7.647564 -0.437990  4.297064     0.0    0.990291"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l2_clfs, c_effect_l2 = compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "c_effect_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bd278a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.041929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.623786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.917476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.750236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.838485</td>\n",
       "      <td>-0.132006</td>\n",
       "      <td>2.163931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.109730</td>\n",
       "      <td>-0.388707</td>\n",
       "      <td>3.992891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.196342</td>\n",
       "      <td>-0.463991</td>\n",
       "      <td>4.595852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c       min       max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.041929  0.000000  0.010482     3.0    0.623786\n",
       "1    0.010 -0.807180  0.000000  0.327752     1.0    0.917476\n",
       "2    0.100 -1.750236  0.000000  0.935861     1.0    0.987864\n",
       "3    1.000 -3.838485 -0.132006  2.163931     0.0    0.987864\n",
       "4   10.000 -7.109730 -0.388707  3.992891     0.0    0.990291\n",
       "5  100.000 -8.196342 -0.463991  4.595852     0.0    0.990291"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running example\n",
    "l1_clfs, c_effect_l1 = compare_c(X_train, y_train, X_test, y_test, p='l1')\n",
    "c_effect_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "**Your thoughts and observations:** \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b68efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller C value may prevent overfitting by reducing variance, but may also increase bias through stronger regularization\n",
    "# bigger C value may lead to overfitting by increasing variance, but may also reduce bias through weaker regularization \n",
    "# L1 penalty may turn some coefficients to zero, potentially reducing overfitting but leading to underfitting with small c value \n",
    "# L2 penalty may shrink some coefficients toward zero but keeps them, therefore not leading to underfitting with small c value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0440979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.85152883, -2.11687242, -2.58471858, -0.13330502]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ea52e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance, skewness, and curtosis have high correlations, while entropy has reltively low correlations \n",
    "# it's probably because entropy is a more general measurement and can be influenced by image quality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9d62802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I really enjoyed writing functions to compare models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
